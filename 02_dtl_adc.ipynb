{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.layers import Activation, Flatten, Dropout, BatchNormalization, Conv2D\n",
    "from tensorflow.keras.layers import AveragePooling2D, Dense, Input, Lambda, concatenate\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = sorted(os.listdir(\"data_organized\"))\n",
    "train_val_patients = []\n",
    "test_patients = []\n",
    "test_count = 0\n",
    "random.shuffle(folders)\n",
    "\n",
    "for name in folders:\n",
    "    train_val_patients.append(name)\n",
    "    \n",
    "for name in folders:\n",
    "    _, count = name.split('+')\n",
    "    # Fill up test_patients with 62 first\n",
    "    count = int(count)\n",
    "    if test_count+count <= 62:\n",
    "        test_patients.append(name)\n",
    "        test_count += count\n",
    "        train_val_patients.remove(name)\n",
    "        if test_count == 62:\n",
    "            break\n",
    "    elif test_count+count > 62:\n",
    "        continue\n",
    "        \n",
    "print(test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in files from folders, store as np arrays of images (X_train) and clinsig labels (y_train)\n",
    "# clinsig TRUE = 1, FALSE = 0\n",
    "X_clinsig = []\n",
    "y_clinsig = []\n",
    "\n",
    "X_indolent = []\n",
    "y_indolent = []\n",
    "\n",
    "for folder in train_val_patients:\n",
    "    for filename in sorted(os.listdir(\"data_organized/{}\".format(folder))):\n",
    "        root, _ = os.path.splitext(filename)\n",
    "        patient, fid, adc_t2, size, zone, label = root.split('+')\n",
    "        img = Image.open(\"data_organized/{}/{}\".format(folder, filename))\n",
    "        img = img.resize((32, 32))\n",
    "        array_gray = np.asarray(img)\n",
    "        array = cv2.merge((array_gray,array_gray,array_gray))    \n",
    "        if adc_t2 == 'adc':\n",
    "            if label == 'TRUE':\n",
    "                X_clinsig.append(array)\n",
    "                y_clinsig.append(1)\n",
    "            else:\n",
    "                X_indolent.append(array)\n",
    "                y_indolent.append(0)\n",
    "\n",
    "# Random over-sampling to remedy imbalanced dataset\n",
    "print('Original: indolent={}, clinsig={}'.format(len(y_indolent), len(y_clinsig)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate imgaes of minority class (clinsig)\n",
    "X = []\n",
    "y = []\n",
    "X.extend(X_indolent)\n",
    "X.extend(X_clinsig)\n",
    "y.extend(y_indolent)\n",
    "y.extend(y_clinsig)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "#                     rescale=1./255,\n",
    "                    shear_range=0.05,\n",
    "#                     zoom_range=[,1],\n",
    "                    rotation_range=90,\n",
    "                    horizontal_flip=True,\n",
    "                    vertical_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "\n",
    "X_clinsig = np.array(X_clinsig)\n",
    "y_clinsig = np.array(y_clinsig)\n",
    "np.asarray(y_clinsig).astype('float32').reshape((-1,1))\n",
    "\n",
    "for img in X_clinsig:\n",
    "    img = img.reshape((1,) + img.shape)\n",
    "    for x, val in zip(datagen.flow(img, batch_size=1), range(2)):\n",
    "        X.append(x[0])\n",
    "        y.append(1)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(Counter(y))\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle(X, y)\n",
    "\n",
    "# Now split this into training and validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=2)\n",
    "\n",
    "#get the length of the train and validation data\n",
    "ntrain = len(X_train)\n",
    "nval = len(X_val)\n",
    "print(\"ntrain={}, nval={}\".format(ntrain, nval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = ResNet50(weights='imagenet', include_top=False, input_shape=(32,32,3))\n",
    "# conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chanDim = 3\n",
    "\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\")) # kernel_initializer=init ? \n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "for i in range(9):\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\")) \n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    \n",
    "model.add(AveragePooling2D(pool_size=(3, 3), padding=\"same\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid')) #Sigmoid function at the end because we have just two classes\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of trainable weights before freezing the conv base:', len(model.trainable_weights))\n",
    "conv_base.trainable = False\n",
    "print('Number of trainable weights after freezing the conv base:', len(model.trainable_weights))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=1e-5), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=[0.7,1],\n",
    "                    horizontal_flip=True,\n",
    "                    vertical_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "print(X_train[0].shape)\n",
    "\n",
    "np.asarray(y_train).astype('float32').reshape((-1,1))\n",
    "np.asarray(y_val).astype('float32').reshape((-1,1))\n",
    "\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=ntrain//batch_size,\n",
    "                    epochs=170,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=nval//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('models/model_adc_weights.h5')\n",
    "model.save('models/model_adc_keras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation and losss\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "#Train and validation accuracy\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "#Train and validation loss\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation and losss with smoother lines\n",
    "\n",
    "def smooth_plot(points, factor=0.7):\n",
    "    smooth_pts = []\n",
    "    for point in points:\n",
    "        if smooth_pts:\n",
    "            previous = smooth_pts[-1]\n",
    "            smooth_pts.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smooth_pts.append(point)\n",
    "    return smooth_pts\n",
    "\n",
    "#Plot figure\n",
    "plt.plot(epochs, smooth_plot(acc), 'b', label='Training accurarcy')\n",
    "plt.plot(epochs, smooth_plot(val_acc), 'r', label='Validation accurarcy')\n",
    "plt.title('Training and Validation accurarcy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, smooth_plot(loss), 'b', label='Training loss')\n",
    "plt.plot(epochs, smooth_plot(val_loss), 'r', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare test set\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for folder in test_patients:\n",
    "    for filename in sorted(os.listdir(\"data_organized/{}\".format(folder))):\n",
    "        root, _ = os.path.splitext(filename)\n",
    "        patient, fid, adc_t2, size, zone, label = root.split('+')\n",
    "        if adc_t2 == 'adc':\n",
    "            if label == 'TRUE':\n",
    "                y_test.append(1)\n",
    "            else:\n",
    "                y_test.append(0)\n",
    "        img = Image.open(\"data_organized/{}/{}\".format(folder, filename))\n",
    "        img = img.resize((32, 32))\n",
    "        array_gray = np.asarray(img)\n",
    "        array = cv2.merge((array_gray,array_gray,array_gray))  \n",
    "        if adc_t2 == 'adc':\n",
    "            X_test.append(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(X_test)\n",
    "y = np.array(y_test)\n",
    "y_pred_class = []\n",
    "y_pred_prob = []\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "correct = 0\n",
    "true_pos = 0\n",
    "true_neg = 0\n",
    "false_pos = 0\n",
    "false_neg = 0\n",
    "i = 0\n",
    "for batch in test_datagen.flow(x, batch_size=1):\n",
    "    if i == len(x):\n",
    "        break\n",
    "    prob = model.predict(batch)\n",
    "    y_pred_prob.append(prob)\n",
    "    prediction = int(np.round(prob))\n",
    "    y_pred_class.append(prediction)\n",
    "    actual = y[i]\n",
    "    if prediction == actual:\n",
    "        correct += 1\n",
    "        if prediction == 1:\n",
    "            true_pos += 1\n",
    "        else:\n",
    "            true_neg += 1\n",
    "    else:\n",
    "        if prediction == 1 and actual == 0:\n",
    "            false_pos += 1\n",
    "        else:\n",
    "            false_neg += 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = np.array(y_pred_prob).reshape((len(y_pred_prob),))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y,y_prob)\n",
    "\n",
    "print('FALSE POSITIVE')\n",
    "print(','.join(str(np.round(x, 3)) for x in fpr))\n",
    "print('TRUE POSITIVE')\n",
    "print(','.join(str(np.round(x, 3)) for x in tpr))\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)\n",
    "\n",
    "print('ACCURACY:', metrics.accuracy_score(y, y_pred_class))\n",
    "print('AUC SCORE:', metrics.roc_auc_score(y,y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_threshold(threshold):\n",
    "    print('Sensitivity:', tpr[thresholds > threshold][-1])\n",
    "    print('Specificity:', 1 - fpr[thresholds > threshold][-1])\n",
    "\n",
    "evaluate_threshold(0.48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = metrics.precision_recall_curve(y,y_prob)\n",
    "print('PRECISION')\n",
    "print(','.join(str(np.round(x, 3)) for x in precision))\n",
    "print()\n",
    "print('RECALL')\n",
    "print(','.join(str(np.round(x, 3)) for x in recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 8))\n",
    "f_scores = np.linspace(0.2, 0.8, num=4)\n",
    "lines = []\n",
    "labels = []\n",
    "for f_score in f_scores:\n",
    "    x = np.linspace(0.01, 1)\n",
    "    y = f_score * x / (2 * x - f_score)\n",
    "    l, = plt.plot(x[y >= 0], y[y >= 0], color='gray', alpha=0.2)\n",
    "    plt.annotate('f1={0:0.1f}'.format(f_score), xy=(0.9, y[45] + 0.02))\n",
    "\n",
    "plt.plot(recall, precision, color='turquoise', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curves')\n",
    "plt.legend(lines, labels, loc=(0, -.38), prop=dict(size=14))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
