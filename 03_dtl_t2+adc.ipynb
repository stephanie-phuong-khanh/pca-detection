{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.layers import Activation, Flatten, Dropout, BatchNormalization, Conv2D\n",
    "from tensorflow.keras.layers import AveragePooling2D, Dense, Input, Lambda, concatenate\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = sorted(os.listdir(\"data_organized\"))\n",
    "train_val_patients = []\n",
    "test_patients = []\n",
    "test_count = 0\n",
    "random.shuffle(folders)\n",
    "\n",
    "for name in folders:\n",
    "    train_val_patients.append(name)\n",
    "    \n",
    "for name in folders:\n",
    "    _, count = name.split('+')\n",
    "    # Fill up test_patients with 62 first\n",
    "    count = int(count)\n",
    "    if test_count+count <= 62:\n",
    "        test_patients.append(name)\n",
    "        test_count += count\n",
    "        train_val_patients.remove(name)\n",
    "        if test_count == 62:\n",
    "            break\n",
    "    elif test_count+count > 62:\n",
    "        continue\n",
    "        \n",
    "print(test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in files from folders, process images, T2 size, zone info, labels\n",
    "# clinsig TRUE = 1, FALSE = 0\n",
    "\n",
    "X_img_t2_clinsig = []\n",
    "X_img_t2_indolent = []\n",
    "y_t2_clinsig = []\n",
    "y_t2_indolent = []\n",
    "\n",
    "X_img_adc_clinsig = []\n",
    "X_img_adc_indolent = []\n",
    "y_adc_clinsig = []\n",
    "y_adc_indolent = []\n",
    "\n",
    "X_size_t2 = []\n",
    "X_zone = []\n",
    "\n",
    "for folder in train_val_patients:\n",
    "    for filename in sorted(os.listdir(\"data_organized/{}\".format(folder))):\n",
    "        root, _ = os.path.splitext(filename)\n",
    "        patient, fid, adc_t2, size, zone, label = root.split('+')\n",
    "        if zone == 'SV': # only 2 data points have this zone\n",
    "            continue\n",
    "        img = Image.open(\"data_organized/{}/{}\".format(folder, filename))\n",
    "        img = img.resize((32, 32))\n",
    "        array_gray = np.asarray(img)\n",
    "        array = cv2.merge((array_gray,array_gray,array_gray))     \n",
    "        if adc_t2 == 't2':\n",
    "            if label == 'TRUE':\n",
    "                X_img_t2_clinsig.append(array)\n",
    "                y_t2_clinsig.append(1)\n",
    "            else:\n",
    "                X_img_t2_indolent.append(array)\n",
    "                y_t2_indolent.append(0)\n",
    "        else:\n",
    "            if label == 'TRUE':\n",
    "                X_img_adc_clinsig.append(array)\n",
    "                y_adc_clinsig.append(1)\n",
    "            else:\n",
    "                X_img_adc_indolent.append(array)\n",
    "                y_adc_indolent.append(0)\n",
    "            \n",
    "\n",
    "# one-hot encode zones, which are categorical features: AS=100, PZ=010, TZ=001\n",
    "X_zone = LabelBinarizer().fit_transform(X_zone)\n",
    "\n",
    "# [0,1] min-max T2 size, which are continuous features\n",
    "X_size_t2 = MinMaxScaler().fit_transform(np.array(X_size_t2).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate images of minority group\n",
    "X_t2 = []\n",
    "X_t2.extend(X_img_t2_clinsig)\n",
    "X_t2.extend(X_img_t2_indolent)\n",
    "y_t2 = []\n",
    "y_t2.extend(y_t2_clinsig)\n",
    "y_t2.extend(y_t2_indolent)\n",
    "\n",
    "X_adc = []\n",
    "X_adc.extend(X_img_adc_clinsig)\n",
    "X_adc.extend(X_img_adc_indolent)\n",
    "y_adc = []\n",
    "y_adc.extend(y_adc_clinsig)\n",
    "y_adc.extend(y_adc_indolent)\n",
    "\n",
    "datagen = ImageDataGenerator(shear_range=0.05,\n",
    "                            rotation_range=90,\n",
    "                            horizontal_flip=True,\n",
    "                            vertical_flip=True,\n",
    "                            fill_mode='nearest')\n",
    "\n",
    "X_t2_clinsig = np.array(X_img_t2_clinsig)\n",
    "X_adc_clinsig = np.array(X_img_adc_clinsig)\n",
    "y_t2_clinsig = np.array(y_t2_clinsig)\n",
    "y_adc_clinsig = np.array(y_adc_clinsig)\n",
    "np.asarray(y_t2_clinsig).astype('float32').reshape((-1,1))\n",
    "np.asarray(y_adc_clinsig).astype('float32').reshape((-1,1))\n",
    "\n",
    "for img in X_t2_clinsig:\n",
    "    img = img.reshape((1,) + img.shape)\n",
    "    for x, val in zip(datagen.flow(img, batch_size=1), range(2)):\n",
    "        X_t2.append(x[0])\n",
    "        y_t2.append(1)\n",
    "        \n",
    "for img in X_adc_clinsig:\n",
    "    img = img.reshape((1,) + img.shape)\n",
    "    for x, val in zip(datagen.flow(img, batch_size=1), range(2)):\n",
    "        X_adc.append(x[0])\n",
    "        y_adc.append(1)\n",
    "\n",
    "X_t2 = np.array(X_t2)\n",
    "X_adc = np.array(X_adc)\n",
    "y_t2 = np.array(y_t2)\n",
    "y_adc = np.array(y_adc)\n",
    "\n",
    "print(Counter(y_t2), Counter(y_adc))\n",
    "print(len(X_t2), len(X_adc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_img_t2 = np.array(X_t2)\n",
    "X_img_adc = np.array(X_adc)\n",
    "X_size_t2 = np.array(X_size_t2)\n",
    "X_zone = np.array(X_zone)\n",
    "y = np.array(y_t2)\n",
    "print('Original: indolent={}, clinsig={}'.format(Counter(y)[0], Counter(y)[1]))\n",
    "\n",
    "print('X_img_t2.shape={}'.format(X_img_t2.shape))\n",
    "print('X_img_adc.shape={}'.format(X_img_adc.shape))\n",
    "print('X_size_t2.shape={}'.format(X_size_t2.shape))\n",
    "print('X_zone.shape={}'.format(X_zone.shape))\n",
    "print('y.shape={}'.format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split this into training and validation set\n",
    "X = list(zip(X_img_t2, X_img_adc, X_size_t2, X_zone))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=2)\n",
    "X_img_t2_train, X_img_adc_train, X_size_t2_train, X_zone_train = zip(*X_train)\n",
    "X_img_t2_val, X_img_adc_val, X_size_t2_val, X_zone_val = zip(*X_val)\n",
    "\n",
    "ntrain = len(X_img_t2_train) # = len(X_size_train) = len(X_zone_train), same for adc\n",
    "nval = len(X_img_t2_val) # = len(X_size_val) = len(X_zone_val), same for adc\n",
    "print(\"ntrain={}, nval={}\".format(ntrain, nval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(width=32, height=32, depth=3):\n",
    "    chanDim = 3\n",
    "    input_tensor = Input(shape=(32, 32, 3))\n",
    "    conv_base = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
    "    conv_base.trainable = False\n",
    "    x = conv_base.output\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization(axis=chanDim)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    for i in range(9):\n",
    "        x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "    \n",
    "    x = AveragePooling2D(pool_size=(3,3), padding=\"same\")(x)\n",
    "    \n",
    "    model = Model(input_tensor, x)\n",
    "    return model\n",
    "\n",
    "def output_size():\n",
    "    inp = Input(shape=(1))\n",
    "    out = Lambda(lambda x: x, output_shape=(1))(inp)\n",
    "    model = Model(inp, out)\n",
    "    \n",
    "def output_zone():\n",
    "    inp = Input(shape=(1,3))\n",
    "    out = Lambda(lambda x: x, output_shape=(1,3))(inp)\n",
    "    model = Model(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_t2 = create_cnn()\n",
    "cnn_adc = create_cnn()\n",
    "dummy_size = output_size()\n",
    "dummy_zone = output_zone()\n",
    "\n",
    "for layer in cnn_t2.layers:\n",
    "    layer._name = layer.name + str(\"_t2\")\n",
    "for layer in cnn_adc.layers:\n",
    "    layer._name = layer.name + str(\"_adc\")\n",
    "\n",
    "combinedInput = concatenate([cnn_t2.output, cnn_adc.output])\n",
    "\n",
    "x = combinedInput\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dense(1, activation=\"sigmoid\", name='predictions')(x)\n",
    "\n",
    "model = Model(inputs=[cnn_t2.input, cnn_adc.input], outputs=x)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = RMSprop(lr=1e-5)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "img_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                 shear_range=0.2,\n",
    "                                 zoom_range=[0.7,1],\n",
    "                                 horizontal_flip=True,\n",
    "                                 vertical_flip=True,\n",
    "                                 fill_mode='nearest')\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "def generate_generator_multiple(generator, x_t2, x_adc, y, batch):\n",
    "    genX1 = generator.flow(x_t2, y, batch_size=batch)\n",
    "    genX2 = generator.flow(x_adc, y, batch_size=batch)\n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        X2i = genX2.next()\n",
    "        yield [X1i[0], X2i[0]], X2i[1]  #Yield both images and their mutual label\n",
    "            \n",
    "X_img_t2_train = np.array(X_img_t2_train)\n",
    "X_img_adc_train = np.array(X_img_adc_train)\n",
    "y_train = np.array(y_train)\n",
    "np.asarray(y_train).astype('float32').reshape((-1,1))\n",
    "\n",
    "X_img_t2_val = np.array(X_img_t2_val)\n",
    "X_img_adc_val = np.array(X_img_adc_val)\n",
    "y_val = np.array(y_val)\n",
    "np.asarray(y_val).astype('float32').reshape((-1,1))\n",
    "\n",
    "img_train_generator = generate_generator_multiple(generator=img_datagen, \n",
    "                                                  x_t2=X_img_t2_train, \n",
    "                                                  x_adc=X_img_adc_train,\n",
    "                                                  y=y_train,\n",
    "                                                  batch=batch_size)\n",
    "img_val_generator = generate_generator_multiple(generator=val_datagen, \n",
    "                                                x_t2=X_img_t2_val, \n",
    "                                                x_adc=X_img_adc_val, \n",
    "                                                y=y_val,\n",
    "                                                batch=batch_size)\n",
    "\n",
    "# train_generator = train_datagen.flow(X_train_img, y_train, batch_size=batch_size)\n",
    "# val_generator = val_datagen.flow(X_val_img, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(img_train_generator,\n",
    "                              steps_per_epoch=ntrain//batch_size,\n",
    "                              epochs=70,\n",
    "                              validation_data=img_val_generator,\n",
    "                              validation_steps=nval//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('models/model_t2+adc_weights.h5')\n",
    "model.save('models/model_t2+adc_keras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation and losss\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "#Train and validation accuracy\n",
    "plt.plot(epochs, acc, 'b', label='Training accurarcy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "#Train and validation loss\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation and losss with smoother lines\n",
    "\n",
    "def smooth_plot(points, factor=0.7):\n",
    "    smooth_pts = []\n",
    "    for point in points:\n",
    "        if smooth_pts:\n",
    "            previous = smooth_pts[-1]\n",
    "            smooth_pts.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smooth_pts.append(point)\n",
    "    return smooth_pts\n",
    "\n",
    "#Plot figure\n",
    "plt.plot(epochs, smooth_plot(acc), 'b', label='Training accurarcy')\n",
    "plt.plot(epochs, smooth_plot(val_acc), 'r', label='Validation accurarcy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, smooth_plot(loss), 'b', label='Training loss')\n",
    "plt.plot(epochs, smooth_plot(val_loss), 'r', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare test set\n",
    "\n",
    "X_t2_test = []\n",
    "X_adc_test = []\n",
    "y_test = []\n",
    "\n",
    "for folder in test_patients:\n",
    "    for filename in sorted(os.listdir(\"data_organized/{}\".format(folder))):\n",
    "        root, _ = os.path.splitext(filename)\n",
    "        patient, fid, adc_t2, size, zone, label = root.split('+')\n",
    "        img = Image.open(\"data_organized/{}/{}\".format(folder, filename))\n",
    "        img = img.resize((32, 32))\n",
    "        array_gray = np.asarray(img)\n",
    "        array = cv2.merge((array_gray,array_gray,array_gray))  \n",
    "        if adc_t2 == 't2':\n",
    "            X_t2_test.append(array)\n",
    "            if label == 'TRUE':\n",
    "                y_test.append(1)\n",
    "            else:\n",
    "                y_test.append(0)\n",
    "        else:\n",
    "            X_adc_test.append(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t2 = np.array(X_t2_test)\n",
    "x_adc = np.array(X_adc_test)\n",
    "y = np.array(y_test)\n",
    "y_pred_class = []\n",
    "y_pred_prob = []\n",
    "total = len(y)\n",
    "\n",
    "clinsig_pred = 0\n",
    "correct = 0\n",
    "true_pos = 0\n",
    "true_neg = 0\n",
    "false_pos = 0\n",
    "false_neg = 0\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "def generate_generator_multiple(generator, x_t2, x_adc, y, batch):\n",
    "    genX1 = generator.flow(x_t2, y, batch_size=batch)\n",
    "    genX2 = generator.flow(x_adc, y, batch_size=batch)\n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        X2i = genX2.next()\n",
    "        yield [X1i[0], X2i[0]], X2i[1]  #Yield both images and their mutual label\n",
    "\n",
    "test_generator = generate_generator_multiple(generator=test_datagen, x_t2=x_t2, x_adc=x_adc, y=y, batch=1)\n",
    "    \n",
    "predictions = model.predict_generator(test_generator, steps=total)\n",
    "for i, pred in enumerate(predictions):\n",
    "    y_pred_prob.append(pred[0])\n",
    "    prediction = 1 if pred[0] > 0.5 else 0\n",
    "    y_pred_class.append(prediction)\n",
    "    actual = y[i] \n",
    "    if prediction == actual:\n",
    "        correct += 1\n",
    "        if prediction == 1:\n",
    "            true_pos += 1\n",
    "        else:\n",
    "            true_neg += 1\n",
    "    else:\n",
    "        if prediction == 1 and actual == 0:\n",
    "            false_pos += 1\n",
    "        else:\n",
    "            false_neg += 1\n",
    "    if prediction:\n",
    "        clinsig_pred += prediction\n",
    "\n",
    "print('PREDICTS CLINSIG: {}%'.format(clinsig_pred/total * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ACCURACY:', metrics.accuracy_score(y, y_pred_class))\n",
    "print('SENSITIVITY:', metrics.recall_score(y, y_pred_class))\n",
    "print('SPECIFICITY:', true_neg / (true_neg + false_pos))\n",
    "\n",
    "y_prob = np.array(y_pred_prob).reshape((len(y_pred_prob),))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y,y_prob)\n",
    "\n",
    "print(','.join(str(x) for x in fpr))\n",
    "print(','.join(str(x) for x in tpr))\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)\n",
    "\n",
    "print('AUC SCORE:', metrics.roc_auc_score(y,y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_threshold(threshold):\n",
    "    print('Sensitivity:', tpr[thresholds > threshold][-1])\n",
    "    print('Specificity:', 1 - fpr[thresholds > threshold][-1])\n",
    "\n",
    "evaluate_threshold(0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = metrics.precision_recall_curve(y,y_prob)\n",
    "print('PRECISION:', ','.join(str(x) for x in precision))\n",
    "print('RECALL', ','.join(str(x) for x in recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 8))\n",
    "f_scores = np.linspace(0.2, 0.8, num=4)\n",
    "lines = []\n",
    "labels = []\n",
    "for f_score in f_scores:\n",
    "    x = np.linspace(0.01, 1)\n",
    "    y = f_score * x / (2 * x - f_score)\n",
    "    l, = plt.plot(x[y >= 0], y[y >= 0], color='gray', alpha=0.2)\n",
    "    plt.annotate('f1={0:0.1f}'.format(f_score), xy=(0.9, y[45] + 0.02))\n",
    "\n",
    "plt.plot(recall, precision, color='turquoise', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curves')\n",
    "plt.legend(lines, labels, loc=(0, -.38), prop=dict(size=14))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
